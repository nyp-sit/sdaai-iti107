{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "xception.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti107/blob/main/session-2/xception-solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e"
      },
      "source": [
        "# Practical Exercise (Optional): Create Modern Modular Network \n",
        "\n",
        "In this exercise, you are going to make use of some architecural elements that you learnt, such as residual connection, and separable convolution, and combine them into a building block, and use this building block to construct a modular network. \n",
        "\n",
        "This building block is similar to what [Xception](https://arxiv.org/abs/1610.02357) is using. \n",
        "\n",
        "Here is the simplified view of our network: \n",
        "\n",
        "![xception](https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/iti107/resources/mini_xception.png)"
      ],
      "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n"
      ],
      "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e403eff-1641-4eb6-8b29-56b124e86156"
      },
      "source": [
        "**Exercise 1**\n",
        "\n",
        "Let us the define our xception block first. Here are the steps you will need to do: \n",
        "1. First save the output from previous block (or if this is the first block, then output from previous convolutional/maxpooling layer) and use this as residual to be added later\n",
        "2. Add the 2 [separable convolutional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D) and the maxpool layer. For MaxPooling,  use a stride size of 2. Add BatchNormalization after each separable convolutional layer and before the Activation layer.\n",
        "3. Use 1x1 conv to adjust the size and channels of the residual to match the output from MaxPooling layer. To adjust the size, you can specify the stride size of 2. \n",
        "4. To add the the residual with the output from MaxPooling layer, you can use the [`keras.layers.add()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add).\n",
        "5. As recommended by author of ResNet, the residual should be added before the Activation function. \n",
        "\n",
        "Use 'same' padding throughout the block."
      ],
      "id": "5e403eff-1641-4eb6-8b29-56b124e86156"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c"
      },
      "source": [
        "def xception_block(x, depth): \n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    x: output from the previous block or previous layer, considered as input to this Xception block\n",
        "       it is a tensor of shape (batch, h, w, channels)\n",
        "    depth: number of channels, it is an int value\n",
        "    \"\"\"\n",
        "    \n",
        "    # save input to be used as skip connection\n",
        "    residual = x \n",
        "    \n",
        "    # add the first separable convolutional 2D layer (as well as the batch normalization and activation layer)\n",
        "    x = keras.layers.SeparableConv2D(depth, 3, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    # add the second separable convolutional 2D layer (as well as the batch normalization BUT without activation layer)\n",
        "    x = keras.layers.SeparableConv2D(depth, 3, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    # add the maxpooling 2d layer, with stride of 2\n",
        "    x = keras.layers.MaxPool2D(3, strides=2, padding='same')(x)\n",
        "    print(x.shape)\n",
        "    \n",
        "    # adjust the size and depth using 1x1 convolution to match the output from last maxpooling layer. Use strides=2 to match the output from maxpooling\n",
        "    residual = keras.layers.Conv2D(depth, 1, strides=2, padding='same')(residual)\n",
        "    \n",
        "    # add the residual\n",
        "    x = keras.layers.add([x, residual])  # Add back residual\n",
        "    \n",
        "    # add the activation layer\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    return x # Set aside next residual"
      ],
      "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c566012b-eb2f-45cd-a60e-826a7a9de9ea"
      },
      "source": [
        "**Exercise 2:**\n",
        "\n",
        "We will then build our complete network using the xception block defined in the previous exercise: \n",
        "1. Define the input layer with appropriate shape\n",
        "2. Define a rescaling layer to normalize the input to between (0,1)\n",
        "3. Define the entry blocks that consist of one Conv2D layer with the stride size of 2 and another Conv2D layer with stride size of 1. Remember to add BatchNormalization after each convolutional layer and before Activation layer.\n",
        "4. Add the series of xception blocks, with different depths `[128,256,512,728]`\n",
        "5. Add the last Separable convolutional 2D layer. Remember to add BatchNormalization layer before the Activation layer.\n",
        "6. Add GlobalAveragePooling2D layer before connected to output Dense Layer\n",
        "7. Use Dropout for the dense layer \n",
        "\n",
        "Use 'same' padding throughout the network.\n",
        "\n"
      ],
      "id": "c566012b-eb2f-45cd-a60e-826a7a9de9ea"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c"
      },
      "source": [
        "def make_model(input_shape, num_classes): \n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = keras.layers.Rescaling(1./255)(inputs)\n",
        "    \n",
        "    # Entry blocks\n",
        "    x = keras.layers.Conv2D(32, 3, strides=2, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    x = keras.layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "    # build a series of xception blocks with different depth\n",
        "    for depth in [128, 256, 512, 728]:\n",
        "        x = xception_block(x, depth)\n",
        "    \n",
        "    # add SeparableConv2D\n",
        "    x = keras.layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
        "\n",
        "    # add Global Average Pooling layer before connecting to Dense layer \n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c",
        "outputId": "f4038640-86c4-4b2d-e5a1-2271caab9363"
      },
      "source": [
        "image_size = (128,128)\n",
        "\n",
        "model = make_model(input_shape= image_size + (3,), num_classes=2)\n",
        "\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 32, 32, 128)\n",
            "(None, 16, 16, 256)\n",
            "(None, 8, 8, 512)\n",
            "(None, 4, 4, 728)\n",
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20393c0b-8e73-47d7-a371-70c61e58cbde"
      },
      "source": [
        "### Create train and validation dataset\n",
        "\n",
        "We will go ahead and download the same dataset, and setup the training and validation dataset."
      ],
      "id": "20393c0b-8e73-47d7-a371-70c61e58cbde"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131"
      },
      "source": [
        "import os \n",
        "\n",
        "dataset_URL = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz'\n",
        "tf.keras.utils.get_file(origin=dataset_URL, extract=True, cache_dir='.')\n",
        "dataset_folder = os.path.join('datasets', 'cats_and_dogs_subset')"
      ],
      "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78",
        "outputId": "db926fc4-c45a-4364-91ac-db4f2615258d"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_folder,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary'\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_folder,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary'\n",
        ")"
      ],
      "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 2 classes.\n",
            "Using 2400 files for training.\n",
            "Found 3000 files belonging to 2 classes.\n",
            "Using 600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef"
      },
      "source": [
        "Ok, everything is ready. Now we are ready to put our mini-xception network to test and see if perform better than our previous 'traditional' CNN architecture. "
      ],
      "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d",
        "outputId": "b32130f0-e7e0-4f76-fcc6-df8568dc416c"
      },
      "source": [
        "def create_tb_callback(): \n",
        "\n",
        "    import os\n",
        "    \n",
        "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
        "\n",
        "    def get_run_logdir():    # use a new directory for each run\n",
        "        \n",
        "        import time\n",
        "        \n",
        "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "        return os.path.join(root_logdir, run_id)\n",
        "\n",
        "    run_logdir = get_run_logdir()\n",
        "\n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "    return tb_callback\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"bestcheckpoint\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "# compile our model with loss and optimizer \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train_ds, epochs=30, \n",
        "    validation_data=val_ds,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")"
      ],
      "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "150/150 [==============================] - 15s 87ms/step - loss: 0.6609 - accuracy: 0.5933 - val_loss: 0.6985 - val_accuracy: 0.4867\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 13s 84ms/step - loss: 0.6238 - accuracy: 0.6571 - val_loss: 0.9405 - val_accuracy: 0.4867\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 14s 90ms/step - loss: 0.6000 - accuracy: 0.6883 - val_loss: 1.5425 - val_accuracy: 0.4867\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 15s 100ms/step - loss: 0.5714 - accuracy: 0.7204 - val_loss: 0.6741 - val_accuracy: 0.6683\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 15s 100ms/step - loss: 0.5378 - accuracy: 0.7387 - val_loss: 0.6586 - val_accuracy: 0.6867\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 15s 100ms/step - loss: 0.4868 - accuracy: 0.7767 - val_loss: 0.7572 - val_accuracy: 0.6900\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 15s 100ms/step - loss: 0.4383 - accuracy: 0.8108 - val_loss: 1.0602 - val_accuracy: 0.6050\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 15s 100ms/step - loss: 0.4021 - accuracy: 0.8225 - val_loss: 0.8541 - val_accuracy: 0.6867\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 15s 98ms/step - loss: 0.3675 - accuracy: 0.8317 - val_loss: 0.8759 - val_accuracy: 0.6933\n",
            "Epoch 10/30\n",
            "150/150 [==============================] - 14s 93ms/step - loss: 0.2988 - accuracy: 0.8821 - val_loss: 0.9232 - val_accuracy: 0.6117\n",
            "Epoch 11/30\n",
            "150/150 [==============================] - 14s 92ms/step - loss: 0.2468 - accuracy: 0.8979 - val_loss: 0.9232 - val_accuracy: 0.7350\n",
            "Epoch 12/30\n",
            "150/150 [==============================] - 14s 91ms/step - loss: 0.2125 - accuracy: 0.9142 - val_loss: 0.9443 - val_accuracy: 0.7217\n",
            "Epoch 13/30\n",
            "150/150 [==============================] - 43s 286ms/step - loss: 0.1941 - accuracy: 0.9208 - val_loss: 0.9696 - val_accuracy: 0.7100\n",
            "Epoch 14/30\n",
            "150/150 [==============================] - 48s 318ms/step - loss: 0.1307 - accuracy: 0.9525 - val_loss: 0.7769 - val_accuracy: 0.7283\n",
            "Epoch 15/30\n",
            "150/150 [==============================] - 48s 319ms/step - loss: 0.1431 - accuracy: 0.9408 - val_loss: 0.8654 - val_accuracy: 0.7517\n",
            "Epoch 16/30\n",
            "150/150 [==============================] - 48s 319ms/step - loss: 0.0969 - accuracy: 0.9638 - val_loss: 0.8995 - val_accuracy: 0.7883\n",
            "Epoch 17/30\n",
            "150/150 [==============================] - 48s 317ms/step - loss: 0.1018 - accuracy: 0.9592 - val_loss: 1.1220 - val_accuracy: 0.7267\n",
            "Epoch 18/30\n",
            "150/150 [==============================] - 48s 317ms/step - loss: 0.0708 - accuracy: 0.9754 - val_loss: 0.9749 - val_accuracy: 0.7533\n",
            "Epoch 19/30\n",
            "150/150 [==============================] - 47s 317ms/step - loss: 0.0911 - accuracy: 0.9671 - val_loss: 0.9957 - val_accuracy: 0.7150\n",
            "Epoch 20/30\n",
            "150/150 [==============================] - 48s 317ms/step - loss: 0.0452 - accuracy: 0.9837 - val_loss: 1.0117 - val_accuracy: 0.7350\n",
            "Epoch 21/30\n",
            "150/150 [==============================] - 48s 317ms/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 1.1188 - val_accuracy: 0.7717\n",
            "Epoch 22/30\n",
            "150/150 [==============================] - 47s 317ms/step - loss: 0.0430 - accuracy: 0.9821 - val_loss: 1.4110 - val_accuracy: 0.7567\n",
            "Epoch 23/30\n",
            "150/150 [==============================] - 48s 317ms/step - loss: 0.0566 - accuracy: 0.9804 - val_loss: 1.0220 - val_accuracy: 0.7800\n",
            "Epoch 24/30\n",
            "150/150 [==============================] - 47s 316ms/step - loss: 0.0412 - accuracy: 0.9854 - val_loss: 1.1547 - val_accuracy: 0.7633\n",
            "Epoch 25/30\n",
            "150/150 [==============================] - 47s 316ms/step - loss: 0.0677 - accuracy: 0.9746 - val_loss: 1.3567 - val_accuracy: 0.7067\n",
            "Epoch 26/30\n",
            "150/150 [==============================] - 47s 317ms/step - loss: 0.0262 - accuracy: 0.9900 - val_loss: 1.8014 - val_accuracy: 0.7550\n",
            "Epoch 27/30\n",
            "150/150 [==============================] - 47s 316ms/step - loss: 0.0581 - accuracy: 0.9779 - val_loss: 1.4235 - val_accuracy: 0.7500\n",
            "Epoch 28/30\n",
            "150/150 [==============================] - 47s 316ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 1.4179 - val_accuracy: 0.7833\n",
            "Epoch 29/30\n",
            "150/150 [==============================] - 47s 316ms/step - loss: 0.0789 - accuracy: 0.9737 - val_loss: 0.8760 - val_accuracy: 0.7683\n",
            "Epoch 30/30\n",
            "150/150 [==============================] - 47s 316ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 1.1741 - val_accuracy: 0.7267\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe184692f40>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0985069-c506-479b-a84e-1e2e5d819de8",
        "outputId": "60ec07e4-0429-4a6a-8510-7d43615faf3a"
      },
      "source": [
        "best_checkpoint = 'bestcheckpoint'\n",
        "\n",
        "model.load_weights(best_checkpoint)\n",
        "model.evaluate(val_ds)"
      ],
      "id": "d0985069-c506-479b-a84e-1e2e5d819de8",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 4s 92ms/step - loss: 0.8995 - accuracy: 0.7883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8994837403297424, 0.7883333563804626]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZpqddmVq-uq"
      },
      "source": [
        ""
      ],
      "id": "tZpqddmVq-uq",
      "execution_count": 30,
      "outputs": []
    }
  ]
}