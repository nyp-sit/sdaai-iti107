{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti107/blob/main/session-3/data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Augmentation (Optional Exercise)\n",
    "\n",
    "Welcome to this week's programming exercise. You will learn to use the Keras ImageDataGenerator to apply different transformations to the image data and observe the effects of the transformations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from utils import prepare_data\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "The function below `prepare_data()` will download a dataset (in zip format) consisting of pictures that depicts Positive and Negative emotions. It automatically unzip and copy the image files into 'Negative' and 'Positive' subfolder in the folder specified by `data_path` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "valid_size = 0.2\n",
    "FORCED_DATA_REWRITE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path, valid_path = prepare_data(data_path=data_path, \n",
    "                                      valid_size=valid_size, \n",
    "                                      FORCED_DATA_REWRITE=FORCED_DATA_REWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_path = os.path.join(train_path, \"Negative\")\n",
    "train_pos_path = os.path.join(train_path, \"Positive\")\n",
    "valid_neg_path = os.path.join(valid_path, \"Negative\")\n",
    "valid_pos_path = os.path.join(valid_path, \"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "positive_expamples = np.random.choice(os.listdir(train_pos_path), size=n_examples, replace=False)\n",
    "negative_expamples = np.random.choice(os.listdir(train_neg_path), size=n_examples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, n_examples * 2))\n",
    "for i in range(n_examples):\n",
    "    plt.subplot(n_examples, 2, i * 2 + 1)\n",
    "    img = load_img(os.path.join(train_pos_path, positive_expamples[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0:\n",
    "        plt.title(\"Positive\", fontsize=18)\n",
    "    plt.subplot(n_examples, 2, i * 2 + 2)\n",
    "    img = load_img(os.path.join(train_neg_path, negative_expamples[i]))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0:\n",
    "        plt.title(\"Negative\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 400, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    if type(img1) == np.ndarray:\n",
    "        img1 = array_to_img(img1)\n",
    "    if type(img2) == np.ndarray:\n",
    "        img2 = array_to_img(img2)\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Original\", fontsize=18)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Transformed\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling \n",
    "\n",
    "The images are usually stored in an RGB (Red Green Blue) format. In this format the image is represented as a three-dimensional (or three-channel) array. \n",
    "One dimension is for channels (red, green, and blue colors) and two other dimensions are spatial dimension. Thus, every pixel is encoded through three numbers. Each number is usually stored as an 8-bit unsigned integer type (0 to 255).\n",
    "\n",
    "Rescaling is an operation that moves your data from one numerical range to another by simple division using a predefined constant. In deep neural networks you might want to restrict your input to the range from 0 to 1, due to possible overflow, optimization, stability issues, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_rescaled = ImageDataGenerator(rescale=1. / 255.)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## class_mode == None will not return any target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_rescaled = datagen_rescaled.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1, \n",
    "                                                    classes=['Positive'],\n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sample_default = next(gen_default)\n",
    "#print(sample_default)\n",
    "sample_rescaled = next(gen_rescaled)\n",
    "compare_images(sample_default[0], sample_rescaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually both images are identical, but that’s just because Python image tools rescale images for displaying. If you look at the raw data, which are arrays, you can see that they differ exactly by a factor of 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sample_default[0][:2, :2, 0]   # examine only the first 2 pixel values of each x, y axis of the first channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sample_rescaled[0][:2, :2, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation\n",
    "\n",
    "This transformation rotates the image in a certain direction (clockwise or counterclockwise).\n",
    "\n",
    "The parameter that allows the rotations is called rotation_range. It specifies the range of rotations in degrees from which the random angle will be chosen uniformly to do a rotation. Note that during the rotation the size of the image remains the same. Thus, some of the image regions will be cropped out and some of the regions of the new image will need to be filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_rotated = ImageDataGenerator(rotation_range=45, fill_mode=\"constant\")\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_rotated = datagen_rotated.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_rotated = next(gen_rotated)\n",
    "compare_images(sample_default[0], sample_rotated[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal shift\n",
    "\n",
    "This transformation shifts the image to a certain direction along the horizontal axis (left or right). The size of the shift can be determined using the width_shift_range parameter and is measured as a fraction of the total width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_hshifted = ImageDataGenerator(width_shift_range=0.4, fill_mode=\"constant\")\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_hshifted = datagen_hshifted.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1, \n",
    "                                                    classes=['Positive'],\n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_hshifted = next(gen_hshifted)\n",
    "compare_images(sample_default[0], sample_hshifted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical shift\n",
    "It shifts the image along the vertical axis (up or down). The parameter through which we can control the range of shift is called the height_shift generator, and is also measured as a fraction of total height.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_vshifted = ImageDataGenerator(height_shift_range=0.5)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1,\n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_vshifted = datagen_vshifted.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1,\n",
    "                                                    classes=['Positive'],\n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_vshifted = next(gen_vshifted)\n",
    "compare_images(sample_default[0], sample_vshifted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shearing\n",
    "\n",
    "Shear mapping or shearing displaces each point in the vertical direction by an amount proportional to its distance from an edge of the image. Note that in general the direction does not have to be vertical and can be arbitrary. The parameter that controls the displacement rate is called shear_range and corresponds to the deviation angle (in radians) between a horizontal line in the original picture and the image (in the mathematical sense) of this line in the transformed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_sheared = ImageDataGenerator(shear_range=30.0)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                   target_size=(img_height, img_width), \n",
    "                                   batch_size=1,\n",
    "                                   classes=['Positive'],\n",
    "                                   shuffle=False, \n",
    "                                   class_mode=None)\n",
    "gen_sheared = datagen_sheared.flow_from_directory(train_path,\n",
    "                                   target_size=(img_height, img_width), \n",
    "                                   batch_size=1,\n",
    "                                   classes=['Positive'],\n",
    "                                   shuffle=False, \n",
    "                                   class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_sheared = next(gen_sheared)\n",
    "compare_images(sample_default[0], sample_sheared[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom\n",
    "\n",
    "This transformation zooms the initial image in or out. The zoom_range parameter controls the zooming factor, it is either a float or \\[lower, upper\\]. If a float, \\[lower, upper\\] = \\[1-zoom_range, 1+zoom_range\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_zoomed = ImageDataGenerator(zoom_range=0.5, fill_mode='constant')\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_zoomed = datagen_zoomed.flow_from_directory(train_path, \n",
    "                                                target_size=(img_height, img_width), \n",
    "                                                batch_size=1, \n",
    "                                                classes=['Positive'],\n",
    "                                                shuffle=False, \n",
    "                                                class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_zoomed = next(gen_zoomed)\n",
    "compare_images(sample_default[0], sample_zoomed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal flip\n",
    "\n",
    "It flips the image with respect to the vertical axis. One can either turn it on or off using the horizontal_flip parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_hflipped = ImageDataGenerator(horizontal_flip=True)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_hflipped = datagen_hflipped.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    classes=['Positive'],\n",
    "                                                    batch_size=1, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_hflipped = next(gen_hflipped)\n",
    "compare_images(sample_default[0], sample_hflipped[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical flip\n",
    "It flips the image with regard to the horizontal axis. The vertical_flip Boolean parameter controls the presence of this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_vflipped = ImageDataGenerator(vertical_flip=True)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  classes=['Positive'],\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_vflipped = datagen_vflipped.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1,\n",
    "                                                    classes=['Positive'],\n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_vflipped = next(gen_vflipped)\n",
    "compare_images(sample_default[0], sample_vflipped[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination\n",
    "\n",
    "Let’s try to apply all the described augmentation transformations simultaneously and see what happens. Recall that the parameters of each of the transformations are chosen randomly from the specified range; thus, we should have a considerably diverse set of samples.\n",
    "\n",
    "Let’s initialize our ImageDataGenerator with all the available options turned on and test it on an image of a red hydrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=45, \n",
    "                             width_shift_range=0.2, \n",
    "                             height_shift_range=0.2, \n",
    "                             shear_range=0.2, \n",
    "                             zoom_range=0.3, \n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True, \n",
    "                             fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img = load_img(os.path.join(train_pos_path, \"Firehydrant2.jpg\"))\n",
    "except:\n",
    "    img = load_img(os.path.join(valid_pos_path, \"Firehydrant2.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_augmentations = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(data_path, \"augmentation_preview\")\n",
    "if os.path.exists(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))    \n",
    "i = 0\n",
    "\n",
    "for batch in datagen.flow(img, \n",
    "                          batch_size=1, \n",
    "                          seed=21, \n",
    "                          save_to_dir=save_dir, \n",
    "                          save_prefix=\"hydrant\", \n",
    "                          save_format=\"jpeg\"):\n",
    "    \n",
    "    plt.subplot(2, int(np.ceil(n_augmentations * 1. / 2)), i + 1)\n",
    "    plt.imshow(array_to_img(batch[0]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    i += 1\n",
    "    if i >= n_augmentations:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tf2env",
   "language": "python",
   "name": "tf2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
